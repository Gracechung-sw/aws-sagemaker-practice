{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c95cd2b",
   "metadata": {},
   "source": [
    "# Model Training with SageMaker Estimator Training Job and track it using Experiments\n",
    "\n",
    "In this notebook we train a Keras model using the MNIST dataset on a remote SageMaker instance using a training job.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb42e3cb",
   "metadata": {},
   "source": [
    "## 개요\n",
    "\n",
    "- [작업 실행 시 필요한 라이브러리 import](#작업-실행-시-필요힌-라이브러리-import)\n",
    "- [SageMaker 세션과 Role, 사용 버킷 정의](#sagemaker-세션과-role-사용-버킷-정의)\n",
    "- [Training script 작성](#training-script-작성)\n",
    "- [Experiment을 생성하고 training job을 실행하기](#experiment을-생성하고-training-job을-실행하기)\n",
    "\n",
    "## Reference\n",
    "\n",
    "- https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-experiments/sagemaker_job_tracking/tensorflow_script_mode_training_job.html\n",
    "- https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-estimator\n",
    "- https://sagemaker.readthedocs.io/en/stable/experiments/sagemaker.experiments.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ce4fb",
   "metadata": {},
   "source": [
    "### 작업 실행 시 필요힌 라이브러리 import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e079c9e2-4410-4374-83ee-e3fe4f6ac650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update boto3 and sagemaker to ensure latest SDK version\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --upgrade boto3\n",
    "!{sys.executable} -m pip install --upgrade sagemaker\n",
    "!{sys.executable} -m pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06038f66-8860-4af1-a6c2-475b52892401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f814b",
   "metadata": {},
   "source": [
    "### SageMaker 세션과 Role, 사용 버킷 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec89d55-64c7-4ecb-9ef6-f13753980ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "boto_session = boto3.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "# SageMaker사용시 log, model artifact 등의 저장을 위해 default로 지정되는 s3를 사용할 수도 있고,\n",
    "# 아니면 직접 s3 세팅해서 이걸 사용하라고 지정해 줄 수도 있습니다.\n",
    "# 실습에서는 default로 제공되는 s3를 사용해보겠습니다.\n",
    "\n",
    "# default bucket이 아니라 직접 만든 s3 bucket을 사용할 수도 있습니다.\n",
    "# 만약 직접 생성한 s3 bucket을 사용할 경우 에러가 난다면 아래의 두 경우일 확률이 높습니다.\n",
    "# 1. bucket이 없는 경우. 즉, bucket을 생성하지 않았는데 그 bucket을 사용하려고 하는 경우\n",
    "# 2. bucket을 생성했지만, role에 해당 bucket에 대한 read, write 권한이 없는 경우\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# sagemaker를 사용\n",
    "sm = boto_session.client(\"sagemaker\")\n",
    "region = boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcebbdd-ead6-49a9-81cb-2c623a7604e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sagemaker_session)\n",
    "print(role)\n",
    "print(default_bucket)\n",
    "print(sm)\n",
    "print(region)  # ex) us-east-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b1a5e",
   "metadata": {},
   "source": [
    "### Training script 작성\n",
    "\n",
    "Here we use a SageMaker Training job to train the model on a remote instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecee201",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./script/train.py\n",
    "\n",
    "# 이렇게 하면 script/train.py 파일이 생성되고, 이 아래에 있는 코드들이 이 파일에 작성된다.\n",
    "\n",
    "import os\n",
    "\n",
    "os.system(\"pip install -U sagemaker\")\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments import load_run\n",
    "\n",
    "import boto3\n",
    "\n",
    "boto_session = boto3.session.Session(region_name=os.environ[\"REGION\"])\n",
    "sagemaker_session = Session(boto_session=boto_session)\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--dropout\", type=float, default=0.01)\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "# Define the Keras callback to log metrics to the run\n",
    "# The Keras Callback class provides a method on_epoch_end which emits metrics at the end of each epoch.\n",
    "# All emitted metrics will be logged in the run passed to the callback.\n",
    "class ExperimentCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, run, trained_model, x_test, y_test):\n",
    "        self.run = run\n",
    "        self.trained_model = trained_model\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        for key in keys:\n",
    "            self.run.log_metric(name=key, value=logs[key], step=epoch)\n",
    "            print(\"{} -> {}\".format(key, logs[key]))\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    num_classes = 10\n",
    "    input_shape = (28, 28, 1)\n",
    "\n",
    "    train_path = \"input_train.npy\"\n",
    "    test_path = \"input_test.npy\"\n",
    "    train_labels_path = \"input_train_labels.npy\"\n",
    "    test_labels_path = \"input_test_labels.npy\"\n",
    "\n",
    "    # Load the data and split it between train and test sets\n",
    "    s3.download_file(\n",
    "        f\"sagemaker-example-files-prod-{os.environ['REGION']}\", \"datasets/image/MNIST/numpy/input_train.npy\", train_path\n",
    "    )\n",
    "    s3.download_file(\n",
    "        f\"sagemaker-example-files-prod-{os.environ['REGION']}\", \"datasets/image/MNIST/numpy/input_test.npy\", test_path\n",
    "    )\n",
    "    s3.download_file(\n",
    "        f\"sagemaker-example-files-prod-{os.environ['REGION']}\",\n",
    "        \"datasets/image/MNIST/numpy/input_train_labels.npy\",\n",
    "        train_labels_path,\n",
    "    )\n",
    "    s3.download_file(\n",
    "        f\"sagemaker-example-files-prod-{os.environ['REGION']}\",\n",
    "        \"datasets/image/MNIST/numpy/input_test_labels.npy\",\n",
    "        test_labels_path,\n",
    "    )\n",
    "\n",
    "    x_train = np.load(train_path)\n",
    "    x_test = np.load(test_path)\n",
    "    y_train = np.load(train_labels_path)\n",
    "    y_test = np.load(test_labels_path)\n",
    "\n",
    "    # Reshape the arrays\n",
    "    x_train = np.reshape(x_train, (60000, 28, 28))\n",
    "    x_test = np.reshape(x_test, (10000, 28, 28))\n",
    "    y_train = np.reshape(y_train, (60000,))\n",
    "    y_test = np.reshape(y_test, (10000,))\n",
    "\n",
    "    # Scale images to the [0, 1] range\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "    # Make sure images have shape (28, 28, 1)\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "    print(\"x_train shape:\", x_train.shape)\n",
    "    print(x_train.shape[0], \"train samples\")\n",
    "    print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\" \"\"\"\n",
    "    args, _ = parse_args()\n",
    "    print(\"Args are : \", args)\n",
    "    num_classes = 10\n",
    "    input_shape = (28, 28, 1)\n",
    "    x_train, x_test, y_train, y_test = load_data()\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(args.dropout),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "    epochs = args.epochs\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    ###\n",
    "    # `load_run` will use the run defined when calling the estimator\n",
    "    ###\n",
    "    with load_run(sagemaker_session=sagemaker_session) as run:\n",
    "        model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.1,\n",
    "            callbacks=[ExperimentCallback(run, model, x_test, y_test)],\n",
    "        )\n",
    "\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(\"Test loss:\", score[0])\n",
    "        print(\"Test accuracy:\", score[1])\n",
    "\n",
    "        run.log_metric(name=\"Final Test Loss\", value=score[0])\n",
    "        run.log_metric(name=\"Final Test Accuracy\", value=score[1])\n",
    "\n",
    "        model.save(\"/opt/ml/model\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8063c278",
   "metadata": {},
   "source": [
    "### Experiment을 생성하고 training job을 실행하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303fbea-268b-4766-abf7-05a3c6679722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from sagemaker.experiments.run import Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f650f-30b1-4c96-a321-a2a4cdb8be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiment_name = \"tensorflow-estimator-experiment-practice\"\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 5\n",
    "dropout = 0.1\n",
    "\n",
    "with Run(\n",
    "    experiment_name=experiment_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    run.log_parameter(\"batch_size\", batch_size)\n",
    "    run.log_parameter(\"epochs\", epochs)\n",
    "    run.log_parameter(\"dropout\", dropout)\n",
    "\n",
    "    # Estimator를 사용하지 않는다면, 여기에 ../2.experiment_training/keras_experiment.ipynb의 def get_model(dropout=0.5): 처럼 model training 코드를 작성하겠지만\n",
    "    # 여기서는 Estimator의 from sagemaker.tensorflow.estimator import TensorFlow를 사용해서\n",
    "    # 추상화된 컨데이너를 사용하도록 코드를 작성합니다.\n",
    "    est = TensorFlow(  # TensorFlow Estimator. https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-estimator\n",
    "        entry_point=\"./script/train.py\",\n",
    "        role=role,\n",
    "        model_dir=False,\n",
    "        # 주의: hyperparameters가 entry_point의 script(\"./script/train.py\")에서 사용하는 인자와 일치해야 합니다.\n",
    "        # Estimator가 \"./script/train.py\" 에서 이 hyperparameters를 인자로 자신의 script에 넣어주기 때문입니다.\n",
    "        # def parse_args():\n",
    "        #     parser = argparse.ArgumentParser()\n",
    "\n",
    "        #     parser.add_argument(\"--epochs\", type=int, default=1)\n",
    "        #     parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "        #     parser.add_argument(\"--dropout\", type=float, default=0.01)\n",
    "\n",
    "        #     return parser.parse_known_args()\n",
    "        hyperparameters={\"epochs\": epochs,\n",
    "                         \"batch_size\": batch_size, \"dropout\": dropout},\n",
    "        framework_version=\"2.8\",  # tensorflow framework version\n",
    "        py_version=\"py39\",  # python version\n",
    "        instance_type=\"ml.m5.xlarge\",\n",
    "        instance_count=1,\n",
    "        keep_alive_period_in_seconds=3600,\n",
    "        environment={\"REGION\": region},\n",
    "    )\n",
    "\n",
    "    # Training Job 시작\n",
    "    # .fit을 호출하면, AWS SageMaker는 자동으로 Estimator를 기반으로 필요한 인프라를 provisioning하고 training job이 생성되어 학습을 실행시킨다.\n",
    "    est.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998a5d5-8841-4c3c-840a-0bb0017279ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 완료시킨 Model을 생성시켜보자.\n",
    "from sagemaker.tensorflow.model import TensorFlowModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e60f0-1fc9-46da-acad-19ad1a41166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TensorFlowModel(model_data=est.model_data,\n",
    "                        role=role, framework_version=\"2.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df50c8b1-48a3-47e5-8ed1-f83858801b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960f624-1359-441b-b546-a0718182f0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693aba2-7ae0-4a70-924a-d516916208f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
